{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Airlines tweets sentiments classification\n",
    "## by J. E. Blanchet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jeblanch\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "import numpy as np \n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "#Need punkt to make text cleaning def properly working\n",
    "nltk.download('punkt')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, auc, roc_auc_score\n",
    "from sklearn.externals import joblib\n",
    "import scipy\n",
    "from scipy.sparse import hstack\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_auc_score\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"pastel\")\n",
    "\n",
    "#Keras CNN, RNN stuff\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import SpatialDropout1D \n",
    "from keras.layers import concatenate\n",
    "from keras.layers import GRU \n",
    "from keras.layers import Bidirectional\n",
    "from keras.layers import GlobalAveragePooling1D\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint \n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)]\n",
      "scipy: 1.3.1\n",
      "numpy: 1.16.5\n",
      "matplotlib: 3.1.1\n",
      "pandas: 0.25.1\n",
      "sklearn: 0.21.3\n",
      "keras: 2.3.1\n",
      "tensorflow: 2.0.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Python: {}'.format(sys.version))\n",
    "import scipy\n",
    "print('scipy: {}'.format(scipy.__version__))\n",
    "import numpy\n",
    "print('numpy: {}'.format(numpy.__version__))\n",
    "import matplotlib\n",
    "print('matplotlib: {}'.format(matplotlib.__version__))\n",
    "import pandas\n",
    "print('pandas: {}'.format(pandas.__version__))\n",
    "import sklearn\n",
    "print('sklearn: {}'.format(sklearn.__version__))\n",
    "import keras\n",
    "print('keras: {}'.format(keras.__version__))\n",
    "import tensorflow\n",
    "print('tensorflow: {}'.format(tensorflow.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pd.read_csv(\"C:/Users/jeblanch/Downloads/Tweets.csv\")\n",
    "DATA = DATA.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet_id', 'airline_sentiment', 'airline_sentiment_confidence',\n",
       "       'negativereason', 'negativereason_confidence', 'airline',\n",
       "       'airline_sentiment_gold', 'name', 'negativereason_gold',\n",
       "       'retweet_count', 'text', 'tweet_coord', 'tweet_created',\n",
       "       'tweet_location', 'user_timezone'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>4794</td>\n",
       "      <td>569731104070115329</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>JasmineDT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>@SouthwestAir you're my early frontrunner for ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-22 21:30:54 -0800</td>\n",
       "      <td>Washington D.C.</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10480</td>\n",
       "      <td>569263373092823040</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Cancelled Flight</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ElizabethFrayer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways how is it that my flt to EWR was Ca...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 14:32:19 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8067</td>\n",
       "      <td>568818669024907264</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Late Flight</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The_Radifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue what is going on with your BDL to DCA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 09:05:13 -0800</td>\n",
       "      <td>Arlington, VA</td>\n",
       "      <td>Atlantic Time (Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8880</td>\n",
       "      <td>567775864679456768</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rnlewisjr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue do they have to depart from Washingto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-17 12:01:29 -0800</td>\n",
       "      <td>iPhone: 60.495510,-151.064590</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8292</td>\n",
       "      <td>568526521910079488</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>beantoon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue I can probably find some of them. Are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 13:44:20 -0800</td>\n",
       "      <td>Plymouth,  MA</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>927</td>\n",
       "      <td>570008443626647552</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kabell87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united still waiting to hear back. My wallet ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 15:52:57 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3165</td>\n",
       "      <td>568622671287566336</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Cancelled Flight</td>\n",
       "      <td>0.6871</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>stephaniefoos</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united Yes my flight was rebooked. I'm just l...</td>\n",
       "      <td>[40.69522398, -74.1760931]</td>\n",
       "      <td>2015-02-19 20:06:23 -0800</td>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>Alaska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7894</td>\n",
       "      <td>569076569983086592</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delta</td>\n",
       "      <td>NaN</td>\n",
       "      <td>theycallme_HH</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@JetBlue Thank you ! What about Paris ? Could ...</td>\n",
       "      <td>[0.0, 0.0]</td>\n",
       "      <td>2015-02-21 02:10:01 -0800</td>\n",
       "      <td>Orleans/Tarpon Springs/London</td>\n",
       "      <td>Amsterdam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2818</td>\n",
       "      <td>568884344221081600</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>United</td>\n",
       "      <td>NaN</td>\n",
       "      <td>andreamvdlg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@united not 100% sure, however my ticket inclu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 13:26:11 -0800</td>\n",
       "      <td>Edinbrah</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9145</td>\n",
       "      <td>570119853312311296</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GrahamHaigh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@usairways great crew for flight 504 PHX to YV...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-23 23:15:40 -0800</td>\n",
       "      <td>Vancouver, Canada</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8983</td>\n",
       "      <td>570303720308809728</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Customer Service Issue</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jhazelnut</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways I've been on hold to change a date ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:26:17 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5333</td>\n",
       "      <td>569184833361936387</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BavarianLin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir I DM'd you</td>\n",
       "      <td>[30.26196639, -97.75945775]</td>\n",
       "      <td>2015-02-21 09:20:13 -0800</td>\n",
       "      <td>New Jersey / Munich</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5821</td>\n",
       "      <td>568572506300243968</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>walterbiscardi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir Already signed up!  Thanks!  Loo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-19 16:47:03 -0800</td>\n",
       "      <td>Atlanta</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5460</td>\n",
       "      <td>568975192615223296</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Southwest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>mmillanjr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@SouthwestAir it was 3472</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-20 19:27:11 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10397</td>\n",
       "      <td>569332237138841600</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>US Airways</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MattClement</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@USAirways Oh well. I'll get to Cancun eventua...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-21 19:05:57 -0800</td>\n",
       "      <td>Troy, NY</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "4794   569731104070115329          positive                        1.0000   \n",
       "10480  569263373092823040          negative                        1.0000   \n",
       "8067   568818669024907264          negative                        1.0000   \n",
       "8880   567775864679456768           neutral                        1.0000   \n",
       "8292   568526521910079488          negative                        0.6625   \n",
       "927    570008443626647552          negative                        1.0000   \n",
       "3165   568622671287566336          negative                        1.0000   \n",
       "7894   569076569983086592           neutral                        1.0000   \n",
       "2818   568884344221081600          negative                        0.6869   \n",
       "9145   570119853312311296          positive                        1.0000   \n",
       "8983   570303720308809728          negative                        1.0000   \n",
       "5333   569184833361936387           neutral                        0.6843   \n",
       "5821   568572506300243968          positive                        1.0000   \n",
       "5460   568975192615223296           neutral                        0.6535   \n",
       "10397  569332237138841600          positive                        0.3502   \n",
       "\n",
       "               negativereason  negativereason_confidence     airline  \\\n",
       "4794                      NaN                        NaN   Southwest   \n",
       "10480        Cancelled Flight                     1.0000  US Airways   \n",
       "8067              Late Flight                     0.6770       Delta   \n",
       "8880                      NaN                        NaN       Delta   \n",
       "8292   Customer Service Issue                     0.3394       Delta   \n",
       "927                Can't Tell                     0.3477      United   \n",
       "3165         Cancelled Flight                     0.6871      United   \n",
       "7894                      NaN                        NaN       Delta   \n",
       "2818               Can't Tell                     0.3434      United   \n",
       "9145                      NaN                        NaN  US Airways   \n",
       "8983   Customer Service Issue                     1.0000  US Airways   \n",
       "5333                      NaN                     0.0000   Southwest   \n",
       "5821                      NaN                        NaN   Southwest   \n",
       "5460                      NaN                     0.0000   Southwest   \n",
       "10397                     NaN                     0.0000  US Airways   \n",
       "\n",
       "      airline_sentiment_gold             name negativereason_gold  \\\n",
       "4794                     NaN        JasmineDT                 NaN   \n",
       "10480                    NaN  ElizabethFrayer                 NaN   \n",
       "8067                     NaN     The_Radifier                 NaN   \n",
       "8880                     NaN        rnlewisjr                 NaN   \n",
       "8292                     NaN         beantoon                 NaN   \n",
       "927                      NaN         kabell87                 NaN   \n",
       "3165                     NaN    stephaniefoos                 NaN   \n",
       "7894                     NaN    theycallme_HH                 NaN   \n",
       "2818                     NaN      andreamvdlg                 NaN   \n",
       "9145                     NaN      GrahamHaigh                 NaN   \n",
       "8983                     NaN        jhazelnut                 NaN   \n",
       "5333                     NaN      BavarianLin                 NaN   \n",
       "5821                     NaN   walterbiscardi                 NaN   \n",
       "5460                     NaN        mmillanjr                 NaN   \n",
       "10397                    NaN      MattClement                 NaN   \n",
       "\n",
       "       retweet_count                                               text  \\\n",
       "4794               1  @SouthwestAir you're my early frontrunner for ...   \n",
       "10480              0  @USAirways how is it that my flt to EWR was Ca...   \n",
       "8067               0  @JetBlue what is going on with your BDL to DCA...   \n",
       "8880               0  @JetBlue do they have to depart from Washingto...   \n",
       "8292               0  @JetBlue I can probably find some of them. Are...   \n",
       "927                0  @united still waiting to hear back. My wallet ...   \n",
       "3165               0  @united Yes my flight was rebooked. I'm just l...   \n",
       "7894               0  @JetBlue Thank you ! What about Paris ? Could ...   \n",
       "2818               0  @united not 100% sure, however my ticket inclu...   \n",
       "9145               0  @usairways great crew for flight 504 PHX to YV...   \n",
       "8983               0  @USAirways I've been on hold to change a date ...   \n",
       "5333               0                           @SouthwestAir I DM'd you   \n",
       "5821               0  @SouthwestAir Already signed up!  Thanks!  Loo...   \n",
       "5460               0                          @SouthwestAir it was 3472   \n",
       "10397              0  @USAirways Oh well. I'll get to Cancun eventua...   \n",
       "\n",
       "                       tweet_coord              tweet_created  \\\n",
       "4794                           NaN  2015-02-22 21:30:54 -0800   \n",
       "10480                          NaN  2015-02-21 14:32:19 -0800   \n",
       "8067                           NaN  2015-02-20 09:05:13 -0800   \n",
       "8880                           NaN  2015-02-17 12:01:29 -0800   \n",
       "8292                           NaN  2015-02-19 13:44:20 -0800   \n",
       "927                            NaN  2015-02-23 15:52:57 -0800   \n",
       "3165    [40.69522398, -74.1760931]  2015-02-19 20:06:23 -0800   \n",
       "7894                    [0.0, 0.0]  2015-02-21 02:10:01 -0800   \n",
       "2818                           NaN  2015-02-20 13:26:11 -0800   \n",
       "9145                           NaN  2015-02-23 23:15:40 -0800   \n",
       "8983                           NaN  2015-02-24 11:26:17 -0800   \n",
       "5333   [30.26196639, -97.75945775]  2015-02-21 09:20:13 -0800   \n",
       "5821                           NaN  2015-02-19 16:47:03 -0800   \n",
       "5460                           NaN  2015-02-20 19:27:11 -0800   \n",
       "10397                          NaN  2015-02-21 19:05:57 -0800   \n",
       "\n",
       "                      tweet_location               user_timezone  \n",
       "4794                Washington D.C.   Eastern Time (US & Canada)  \n",
       "10480                            NaN                         NaN  \n",
       "8067                   Arlington, VA      Atlantic Time (Canada)  \n",
       "8880   iPhone: 60.495510,-151.064590                      Alaska  \n",
       "8292                   Plymouth,  MA                         NaN  \n",
       "927                              NaN                         NaN  \n",
       "3165                      Boston, MA                      Alaska  \n",
       "7894   Orleans/Tarpon Springs/London                   Amsterdam  \n",
       "2818                       Edinbrah   Eastern Time (US & Canada)  \n",
       "9145               Vancouver, Canada  Pacific Time (US & Canada)  \n",
       "8983                             NaN                         NaN  \n",
       "5333             New Jersey / Munich  Eastern Time (US & Canada)  \n",
       "5821                         Atlanta  Eastern Time (US & Canada)  \n",
       "5460                             NaN                         NaN  \n",
       "10397                       Troy, NY  Eastern Time (US & Canada)  "
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = pd.read_csv(\"C:/Users/jeblanch/Downloads/Tweets.csv\", encoding='latin1', \n",
    "usecols=['text', 'airline_sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['airline_sentiment', 'text'], dtype='object')"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>negative</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14635</td>\n",
       "      <td>positive</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14636</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14637</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14638</td>\n",
       "      <td>negative</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14639</td>\n",
       "      <td>neutral</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      airline_sentiment                                               text\n",
       "0               neutral                @VirginAmerica What @dhepburn said.\n",
       "1              positive  @VirginAmerica plus you've added commercials t...\n",
       "2               neutral  @VirginAmerica I didn't today... Must mean I n...\n",
       "3              negative  @VirginAmerica it's really aggressive to blast...\n",
       "4              negative  @VirginAmerica and it's a really big bad thing...\n",
       "...                 ...                                                ...\n",
       "14635          positive  @AmericanAir thank you we got on a different f...\n",
       "14636          negative  @AmericanAir leaving over 20 minutes Late Flig...\n",
       "14637           neutral  @AmericanAir Please bring American Airlines to...\n",
       "14638          negative  @AmericanAir you have my money, you change my ...\n",
       "14639           neutral  @AmericanAir we have 8 ppl so we need 2 know h...\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14635</td>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14636</td>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14637</td>\n",
       "      <td>@AmericanAir Please bring American Airlines to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14638</td>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14639</td>\n",
       "      <td>@AmericanAir we have 8 ppl so we need 2 know h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14640 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  target\n",
       "0                    @VirginAmerica What @dhepburn said.       1\n",
       "1      @VirginAmerica plus you've added commercials t...       2\n",
       "2      @VirginAmerica I didn't today... Must mean I n...       1\n",
       "3      @VirginAmerica it's really aggressive to blast...       0\n",
       "4      @VirginAmerica and it's a really big bad thing...       0\n",
       "...                                                  ...     ...\n",
       "14635  @AmericanAir thank you we got on a different f...       2\n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...       0\n",
       "14637  @AmericanAir Please bring American Airlines to...       1\n",
       "14638  @AmericanAir you have my money, you change my ...       0\n",
       "14639  @AmericanAir we have 8 ppl so we need 2 know h...       1\n",
       "\n",
       "[14640 rows x 2 columns]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "DATA['target'] = le.fit_transform(DATA['airline_sentiment'])\n",
    "DATA=DATA.drop(['airline_sentiment'], axis=1)\n",
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14640, 2)\n"
     ]
    }
   ],
   "source": [
    "print(DATA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9178\n",
       "1    3099\n",
       "2    2363\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA['target'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More advanced text cleaning for none embedding machine learning approches (bag of word (counter & vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "apostrophe_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "punct_dict = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n",
    "mispell_dict = {'colour': 'color', 'centre': 'center', 'favourite': 'favorite', 'travelling': 'traveling', 'counselling': 'counseling', 'theatre': 'theater', 'cancelled': 'canceled', 'labour': 'labor', 'organisation': 'organization', 'wwii': 'world war 2', 'citicise': 'criticize', 'youtu ': 'youtube ', 'Qoura': 'Quora', 'sallary': 'salary', 'Whta': 'What', 'narcisist': 'narcissist', 'howdo': 'how do', 'whatare': 'what are', 'howcan': 'how can', 'howmuch': 'how much', 'howmany': 'how many', 'whydo': 'why do', 'doI': 'do I', 'theBest': 'the best', 'howdoes': 'how does', 'mastrubation': 'masturbation', 'mastrubate': 'masturbate', \"mastrubating\": 'masturbating', 'pennis': 'penis', 'Etherium': 'Ethereum', 'narcissit': 'narcissist', 'bigdata': 'big data', '2k17': '2017', '2k18': '2018', 'qouta': 'quota', 'exboyfriend': 'ex boyfriend', 'airhostess': 'air hostess', \"whst\": 'what', 'watsapp': 'whatsapp', 'demonitisation': 'demonetization', 'demonitization': 'demonetization', 'demonetisation': 'demonetization'}\n",
    "\n",
    "def clean_apostrophe(x, apos_dict):\n",
    "    x = ' '.join([apos_dict[t] if t in apos_dict else t for t in x.split(\" \")])\n",
    "    return x\n",
    "DATA['text'] = DATA['text'].apply(lambda y: clean_apostrophe(y, apostrophe_dict))\n",
    "\n",
    "def clean_apostrophe(x, apos_dict):\n",
    "    x = ' '.join([apos_dict[t] if t in apos_dict else t for t in x.split(\" \")])\n",
    "    return x\n",
    "DATA['text'] = DATA['text'].apply(lambda y: clean_apostrophe(y, apostrophe_dict))\n",
    "\n",
    "def clean_apostrophe(x, apos_dict):\n",
    "    x = ' '.join([apos_dict[t] if t in apos_dict else t for t in x.split(\" \")])\n",
    "    return x\n",
    "DATA['text'] = DATA['text'].apply(lambda y: clean_apostrophe(y, apostrophe_dict))\n",
    "\n",
    "def cleantext1(x):\n",
    "    \n",
    "    x = re.sub(r'http\\S+', '', x)\n",
    "    x = re.sub(r\"#(\\w+)\", '', x)\n",
    "    x = re.sub(r\"@(\\w+)\", '', x)\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    x = re.sub(r'[^\\x20-\\x7e]',r'', x)\n",
    "\n",
    "    x = re.sub('[0-9]{5,}', '#####', x)\n",
    "    x = re.sub('[0-9]{4}', '####', x)\n",
    "    x = re.sub('[0-9]{3}', '###', x)\n",
    "    x = re.sub('[0-9]{2}',\"##\",x)\n",
    "    \n",
    "    x = x.strip().lower()\n",
    "    \n",
    "    #Emojies cleaning\n",
    "    x = re.compile(\"[\"\n",
    "                    u\"\\U0001F600-\\U0001F64F\"\n",
    "                    u\"\\U0001F300-\\U0001F5FF\"\n",
    "                    u\"\\U0001F680-\\U0001F6FF\"\n",
    "                    u\"\\U0001F1E0-\\U0001F1FF\"\n",
    "                    u\"\\U00002702-\\U000027B0\"\n",
    "                    u\"\\U000024C2-\\U0001F251\"\n",
    "                    u\"\\U0001f926-\\U0001f937\"\n",
    "                    u'\\U00010000-\\U0010ffff'\n",
    "                    u\"\\u200d\"\n",
    "                    u\"\\u2640-\\u2642\"\n",
    "                    u\"\\u2600-\\u2B55\"\n",
    "                    u\"\\u23cf\"\n",
    "                    u\"\\u23e9\"\n",
    "                    u\"\\u231a\"\n",
    "                    u\"\\u3030\"\n",
    "                    u\"\\ufe0f\"\n",
    "                    \"]+\", flags=re.UNICODE).sub(r'', x)\n",
    "    \n",
    "    x = word_tokenize(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "DATA['textt'] = DATA['text'].apply(lambda x: cleantext1(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More basic text cleaning for embedding machine learning approaches (rnn, cnn, rnn+cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleantext2(y):\n",
    "    \n",
    "    x = re.sub(r'http\\S+', '', x)\n",
    "    x = re.sub(r\"#(\\w+)\", '', x)\n",
    "    x = re.sub(r\"@(\\w+)\", '', x)\n",
    "    x = re.sub(r'[^\\w\\s]', '', x)\n",
    "    x = re.sub(r'[^\\x20-\\x7e]',r'', x)   \n",
    "    x = x.strip().lower()\n",
    "    x = word_tokenize(x)\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "      <th>textt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>1</td>\n",
       "      <td>[what, said]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>@VirginAmerica plus you have added commercials...</td>\n",
       "      <td>2</td>\n",
       "      <td>[plus, you, have, added, commercials, to, the,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>@VirginAmerica I did not today... Must mean I ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[i, did, not, today, must, mean, i, need, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@VirginAmerica it is really aggressive to blas...</td>\n",
       "      <td>0</td>\n",
       "      <td>[it, is, really, aggressive, to, blast, obnoxi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@VirginAmerica and it is a really big bad thin...</td>\n",
       "      <td>0</td>\n",
       "      <td>[and, it, is, a, really, big, bad, thing, abou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>0</td>\n",
       "      <td>[seriously, would, pay, #, #, a, flight, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>2</td>\n",
       "      <td>[yes, nearly, every, time, i, fly, vx, this, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>1</td>\n",
       "      <td>[really, missed, a, prime, opportunity, for, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>@virginamerica Well, I didn'tâ¦but NOW I DO! :-D</td>\n",
       "      <td>2</td>\n",
       "      <td>[well, i, didntbut, now, i, do, d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>2</td>\n",
       "      <td>[it, was, amazing, and, arrived, an, hour, ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>@VirginAmerica did you know that suicide is th...</td>\n",
       "      <td>1</td>\n",
       "      <td>[did, you, know, that, suicide, is, the, secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>@VirginAmerica I &amp;lt;3 pretty graphics. so muc...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, lt3, pretty, graphics, so, much, better, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>@VirginAmerica This is such a great deal! Alre...</td>\n",
       "      <td>2</td>\n",
       "      <td>[this, is, such, a, great, deal, already, thin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>@VirginAmerica @virginmedia I am flying your #...</td>\n",
       "      <td>2</td>\n",
       "      <td>[i, am, flying, your, skies, again, u, take, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>@VirginAmerica Thanks!</td>\n",
       "      <td>2</td>\n",
       "      <td>[thanks]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  target  \\\n",
       "0                 @VirginAmerica What @dhepburn said.       1   \n",
       "1   @VirginAmerica plus you have added commercials...       2   \n",
       "2   @VirginAmerica I did not today... Must mean I ...       1   \n",
       "3   @VirginAmerica it is really aggressive to blas...       0   \n",
       "4   @VirginAmerica and it is a really big bad thin...       0   \n",
       "5   @VirginAmerica seriously would pay $30 a fligh...       0   \n",
       "6   @VirginAmerica yes, nearly every time I fly VX...       2   \n",
       "7   @VirginAmerica Really missed a prime opportuni...       1   \n",
       "8   @virginamerica Well, I didn'tâ¦but NOW I DO! :-D       2   \n",
       "9   @VirginAmerica it was amazing, and arrived an ...       2   \n",
       "10  @VirginAmerica did you know that suicide is th...       1   \n",
       "11  @VirginAmerica I &lt;3 pretty graphics. so muc...       2   \n",
       "12  @VirginAmerica This is such a great deal! Alre...       2   \n",
       "13  @VirginAmerica @virginmedia I am flying your #...       2   \n",
       "14                             @VirginAmerica Thanks!       2   \n",
       "\n",
       "                                                textt  \n",
       "0                                        [what, said]  \n",
       "1   [plus, you, have, added, commercials, to, the,...  \n",
       "2   [i, did, not, today, must, mean, i, need, to, ...  \n",
       "3   [it, is, really, aggressive, to, blast, obnoxi...  \n",
       "4   [and, it, is, a, really, big, bad, thing, abou...  \n",
       "5   [seriously, would, pay, #, #, a, flight, for, ...  \n",
       "6   [yes, nearly, every, time, i, fly, vx, this, e...  \n",
       "7   [really, missed, a, prime, opportunity, for, m...  \n",
       "8                  [well, i, didntbut, now, i, do, d]  \n",
       "9   [it, was, amazing, and, arrived, an, hour, ear...  \n",
       "10  [did, you, know, that, suicide, is, the, secon...  \n",
       "11  [i, lt3, pretty, graphics, so, much, better, t...  \n",
       "12  [this, is, such, a, great, deal, already, thin...  \n",
       "13  [i, am, flying, your, skies, again, u, take, a...  \n",
       "14                                           [thanks]  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it',\n",
       " 'is',\n",
       " 'really',\n",
       " 'aggressive',\n",
       " 'to',\n",
       " 'blast',\n",
       " 'obnoxious',\n",
       " 'entertainment',\n",
       " 'in',\n",
       " 'your',\n",
       " 'guests',\n",
       " 'faces',\n",
       " 'amp',\n",
       " 'they',\n",
       " 'have',\n",
       " 'little',\n",
       " 'recourse']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA.textt[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = DATA['target']\n",
    "x_train, x_test, y_train, y_test = train_test_split(DATA['textt'], \n",
    "                                                target, test_size=0.2, random_state=42, stratify=DATA['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[thank, you]                                                                                                                                                       55\n",
       "[thanks]                                                                                                                                                           48\n",
       "[our, fleets, on, fleek]                                                                                                                                           14\n",
       "[rt, our, fleets, on, fleek]                                                                                                                                       10\n",
       "[s, ceo, battles, to, appease, passengers, and, wall, street, waterbury, republican, american]                                                                      8\n",
       "                                                                                                                                                                   ..\n",
       "[also, group, 5, is, total, bs]                                                                                                                                     1\n",
       "[#, #, #, #, dcabos, cancelled, flightled, after, making, us, wait, over, an, hour, if, i, fly, usair, every, week, can, you, upgrade, my, status, proactively]     1\n",
       "[what, an, incredibly, arrogant, thing, to, say, while, i, sit, here, at, ohare, waiting, for, your, incompetent, airlines, to, refuel, on, a]                      1\n",
       "[thank, u, for, not, leaving, me, nice, job, running, thru, the, airport, to, catch, your, connecting, flight]                                                      1\n",
       "[would, have, been, good, to, know, months, ago, that, you, cancelled, flightled, our, flights, leaving, tomorrow]                                                  1\n",
       "Name: textt, Length: 11386, dtype: int64"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countvectorizer_word = CountVectorizer()\n",
    "countvectorizer_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_word = TfidfVectorizer()\n",
    "vectorizer_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
